{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367fdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESERCIZIO1: SELEZIONARE IL DATASET mappa dei pub, circoli e locali in Italia\n",
    "''' quanti dati ci sono in totale? \n",
    "    quali sono i metadati? \n",
    "    stampare il primo elemento\n",
    "    stampare l'ultimo elemento \n",
    "    riuscire a stampare un elemento a caso \n",
    "    quali sono gli anni di inserimento presenti? \n",
    "    quante attività ci sono nel quadrato di longitudine 9-10 e latitudine 45-46? \n",
    "    quante attività ci sono nella provincia di Vicenza? \n",
    "    quante enoteche ci sono, e come si chiamano?\n",
    "    quante attività ci sono in Lazio e Abruzzo assieme? '''\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = \"Dataset/Mappa-dei-pub-circoli-locali-in-Italia.csv\"\n",
    "df = pd.read_csv(url, encoding=\"latin1\", sep=\";\")\n",
    "\n",
    "print(df.shape) #dimensioni\n",
    "df.info() #metadati\n",
    "df.describe() #anteprima descrittva\n",
    "\n",
    "print(df.head(1)) #primo elemento\n",
    "print(df.tail(1)) #ultimo elemento\n",
    "print(df.sample(1)) #elemento a caso\n",
    "\n",
    "print(df[\"Anno inserimento\"].unique()) #anni di inserimento presenti\n",
    "\n",
    "long_9_10 = (df.loc[:, \"Longitudine\"] >= 9) & (df.loc[:, \"Longitudine\"] <= 10) #filtro longitudine\n",
    "lat_45_46 = (df.loc[:, \"Latitudine\"] >= 45) & (df.loc[:, \"Latitudine\"] <= 46) #filtro latitudine\n",
    "filtro_cord = long_9_10 & lat_45_46\n",
    "attivita = df.loc[filtro_cord]\n",
    "attivita_valori = attivita.value_counts().sum() #conta valori + somma valori\n",
    "\n",
    "print(\"Le attività presenti nel quadrato di longitudine 9-10 e latitudine 45-46 sono:\", attivita_valori) #risultato somma valori\n",
    "\n",
    "filtro_vicenza = df.loc[:, \"Provincia\"] == \"VICENZA\" #filtro provincia\n",
    "vicenza = df.loc[filtro_vicenza] #applicazione filtro\n",
    "vicenza_valori = vicenza.value_counts().sum() #conta e somma valori\n",
    "\n",
    "print(\"Le attività presenti nella provincia di Vicenza sono:\", vicenza_valori)\n",
    "\n",
    "filtro_lazio = df.loc[:, \"Regione\"] == \"Lazio\" #filtro regione1\n",
    "filtro_abruzzo = df.loc[:, \"Regione\"] == \"Abruzzo\" #filtro regione2\n",
    "regioni = filtro_lazio | filtro_abruzzo #filtro regioni\n",
    "regioni_valori = regioni.value_counts().sum() #conta e somma valori \n",
    "\n",
    "print(\"Le attività in Lazio e Abruzzo assieme sono:\", regioni_valori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54064b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESERCIZIO2: SELEZIONARE IL DATASET insurance.csv, che contiene dati rispetto a caratteristiche e abitudini delle persone, e della zona in cui vivono, \n",
    "# rispetto ai costi individuali per le cure mediche come premio per le assicurazioni sulla salute\n",
    "''' visualizzare le dimensioni, un'anteprima, e osservare i nomi di colonna \n",
    "    quali sono le medie di charges rispetto a region? ci sono differenze significative?\n",
    "    e rispetto a smoker? e a sex? \n",
    "    quali sono i descrittori statistici di bmi? quali sono minimo, media e massimo di charges rispetto ai diversi quartili dei valori di bmi? '''\n",
    "\n",
    "import pandas as pd\n",
    "url = \"Dataset/insurance.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.shape) #dimensioni\n",
    "df.info() #metadati\n",
    "df.sample(5) #5 righe a caso\n",
    "\n",
    "region_charges = df.groupby(\"region\")[\"charges\"].mean() #raggruppo per region e calcolo media su charges\n",
    "print(region_charges)\n",
    "\n",
    "smoker_charges = df.groupby(\"smoker\")[\"charges\"].mean() #raggruppo per smoker e calcolo media su charges\n",
    "print(smoker_charges)\n",
    "\n",
    "sex_charges = df.groupby(\"sex\")[\"charges\"].mean() #raggruppo per sex e calcolo media su charges\n",
    "print(sex_charges)\n",
    "\n",
    "bmi = df.groupby(\"bmi\").describe() #descrittori statistici bmi\n",
    "\n",
    "#creo una colonna in cui assegno q1, q2, q3, q4 in base ai quartili di bmi\n",
    "df[\"quartile\"] = None #creazione colonna\n",
    "\n",
    "#filtri\n",
    "quartile1 = (df.loc[:, \"bmi\"] >=15.96) & (df.loc[:, \"bmi\"] <26.29)\n",
    "df.loc[quartile1, \"quartile\"] = \"Q1\"\n",
    "\n",
    "quartile2 = (df.loc[:, \"bmi\"] >=26.29) & (df.loc[:, \"bmi\"] <30.40)\n",
    "df.loc[quartile2, \"quartile\"] = \"Q2\" \\\n",
    "\n",
    "quartile3 = (df.loc[:, \"bmi\"] >=30.40) & (df.loc[:,\"bmi\"] <34.69)\n",
    "df.loc[quartile3, \"quartile\"] = \"Q3\"\n",
    "\n",
    "quartile4 = (df.loc[:, \"bmi\"] >=34.69) & (df.loc[:, \"bmi\"] <=53.13)\n",
    "df.loc[quartile4, \"quartile\"] = \"Q4\"\n",
    "\n",
    "#raggruppo per quartili e \n",
    "bmi_charges = df.groupby(\"quartile\")[\"charges\"].agg([\"min\", \"mean\", \"max\"])\n",
    "\n",
    "print(bmi_charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc4f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESERCIZIO3: SELEZIONARE IL DATASET iris.csv \n",
    "''' calcolare la media lunghezza dei petali di tutto il dataset\n",
    "    calcolare la media lunghezza dei petali per ogni specie di iris (groupby)\n",
    "    calcolare la media, minimo e massimo della larghezza dei sepali per ogni specie (groupby e agg) '''\n",
    "\n",
    "import pandas as pd\n",
    "url =\"Dataset/iris.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.info()\n",
    "df.head(5)\n",
    "\n",
    "df.describe() #media lunghezza di tutti i petali\n",
    "\n",
    "lung_specie = df.groupby(\"species\")[\"petal_length\"].mean() #raggruppo per specie e calcolo la media sulla lunghezza\n",
    "print(lung_specie)\n",
    "\n",
    "larg_specie = df.groupby(\"species\")[\"sepal_width\"].agg([\"min\", \"mean\", \"max\"])\n",
    "print(larg_specie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb59d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESERCIZIO4: SELEZIONARE IL DATASET wine.csv che contiene delle analisi organolettiche su diverse qualità di vini\n",
    "''' qual è la media di concentrazione alcolica per ogni qualità? ci sono differenze? e rispetto alla media totale?\n",
    "    c'è differenza nella concentrazione alcolica per vini bianchi e vini rossi?\n",
    "    rifacendo le analisi dei due punti precedenti ma per il pH, cambia qualcosa?\n",
    "    e per i solfati? '''\n",
    "    \n",
    "import pandas as pd\n",
    "url = \"Dataset/wine.csv\"\n",
    "df = pd.read_csv(url)    \n",
    "\n",
    "df.info()\n",
    "df.sample(5)\n",
    "\n",
    "#CONCENTRAZIONE ALCOHOOL\n",
    "alcohol_qualita = df.groupby(\"quality\")[\"alcohol\"].mean() #raggruppo per qualità e calcolo la media sull'alcohol\n",
    "print(alcohol_qualita)\n",
    "df.describe() #media totale 10.49\n",
    "\n",
    "alcohol_type = df.groupby(\"type\")[\"alcohol\"].sum() #alcohol rossi e bianchi\n",
    "print(alcohol_type)\n",
    "\n",
    "#PH\n",
    "ph_qualita = df.groupby(\"quality\")[\"pH\"].mean() #raggruppo per qualità e calcolo ph di ogni\n",
    "print(ph_qualita)\n",
    "df.describe() #media totale 3.21\n",
    "\n",
    "ph_type = df.groupby(\"type\")[\"pH\"].sum() #ph rossi e bianchi\n",
    "print(ph_type)\n",
    "\n",
    "#SOLFATI\n",
    "solf_qualita = df.groupby(\"quality\")[\"sulphates\"].mean()\n",
    "print(solf_qualita)\n",
    "df.describe() #media di 0.53\n",
    "\n",
    "solf_type = df.groupby(\"type\")[\"sulphates\"].sum()\n",
    "print(solf_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESERCIZIO5: SELEZIONARE IL DATASET boston.csv che contiene il Boston Housing Dataset\n",
    "# che deriva dalle informazioni raccolte dal Census Service degli Stati Uniti sulle abitazioni nell'area di Boston\n",
    "''' la media del prezzo delle case cambia a seconda della distanza dal fiume Charles?\n",
    "    si nota una correlazione tra il tasso di criminalità e il valore delle abitazioni? come si può spiegare il risultato?\n",
    "    qual è la media del numero di stanze rispetto al rapporto alunni-insegnanti? e del valore delle case? appare esserci una qualche correlazione? come si può spiegare il risultato?\n",
    "    rispetto all'accessibilità alle autostrade, cambia qualcosa la media delle età delle abitazioni? e del numero di stanze? e delle tasse? '''\n",
    "\n",
    "import pandas as pd\n",
    "url = \"Dataset/boston.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "df.info()\n",
    "df.sample(5)\n",
    "\n",
    "chas_medv = df.groupby(\"chas\")[\"medv\"].mean() #raggruppo per la distanza del fiume e calcolo media sul prezzo delle case\n",
    "print(chas_medv)\n",
    "\n",
    "df.corr(numeric_only=True) \n",
    "#crim/medv -0.38, correlazione negativa, all'aumentare di una diminuisce l'altra e viceversa\n",
    "\n",
    "ptratio = df.groupby(\"ptratio\")[[\"rm\", \"medv\"]].mean() #raggruppo rapporto a/i e su questo calcolo la media di numero stanze e di valore case\n",
    "print(ptratio)\n",
    "\n",
    "df.corr(numeric_only=True) \n",
    "#ptratio/rm -0.35, correlazione negativa\n",
    "#ptratio/medv -0.50, correlazione negativa\n",
    "\n",
    "rad = df.groupby(\"rad\")[[\"age\", \"medv\", \"tax\"]].mean() #raggruppo per rad e calcolo le tre medie rispetto a rad\n",
    "print(rad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ESERCIZIO6: si ha un dataframe di dipendenti e uno di dipartimenti\n",
    "''' unire questi DataFrame in base alla colonna comune department_id, in modo da avere nel risultato informazioni sia sui dipendenti che sui dipartimenti, usando la funzione .merge()\n",
    "    per ogni DataFrame, trasformare la colonna department_id nell'indice, facendo in modo che la modifica sia permanente; poi unire i due dataset mediante il metodo .join()\n",
    "    ci sono differenze nel risultato? quali? perché? '''\n",
    "\n",
    "employees_df = pd.DataFrame({ 'employee_id': [101, 102, 103, 104, 105], \n",
    "                              'name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'], \n",
    "                              'department_id': [1, 2, 1, 2, 3] })\n",
    "\n",
    "departments_df = pd.DataFrame({ 'department_id': [1, 2, 3],\n",
    "                                'department_name': ['HR', 'IT', 'Finance'],\n",
    "                                'location': ['New York', 'San Francisco', 'Chicago'] })\n",
    "\n",
    "merged = employees_df.merge(departments_df, how=\"left\", on=\"department_id\")\n",
    "print(merged)\n",
    "\n",
    "employees_df = employees_df.set_index(\"department_id\")\n",
    "joined = employees_df.join(departments_df)\n",
    "print(joined)\n",
    "#tra i due metodi, nella join ci sono alcuni valori NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f3aa2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 317 entries, 0 to 316\n",
      "Data columns (total 33 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   ParentEmployeeKey                     316 non-null    float64\n",
      " 1   EmployeeNationalIDAlternateKey        317 non-null    int64  \n",
      " 2   ParentEmployeeNationalIDAlternateKey  316 non-null    float64\n",
      " 3   FirstName                             317 non-null    object \n",
      " 4   LastName                              317 non-null    object \n",
      " 5   MiddleName                            304 non-null    object \n",
      " 6   NameStyle                             317 non-null    int64  \n",
      " 7   Title                                 317 non-null    object \n",
      " 8   HireDate                              317 non-null    object \n",
      " 9   BirthDate                             317 non-null    object \n",
      " 10  LoginID                               317 non-null    object \n",
      " 11  EmailAddress                          317 non-null    object \n",
      " 12  Phone                                 317 non-null    object \n",
      " 13  MaritalStatus                         317 non-null    object \n",
      " 14  EmergencyContactName                  317 non-null    object \n",
      " 15  EmergencyContactPhone                 317 non-null    object \n",
      " 16  SalariedFlag                          317 non-null    int64  \n",
      " 17  Gender                                317 non-null    object \n",
      " 18  PayFrequency                          317 non-null    int64  \n",
      " 19  BaseRate                              317 non-null    float64\n",
      " 20  VacationHours                         317 non-null    int64  \n",
      " 21  SickLeaveHours                        317 non-null    int64  \n",
      " 22  CurrentFlag                           317 non-null    int64  \n",
      " 23  SalesPersonFlag                       317 non-null    int64  \n",
      " 24  DepartmentName                        317 non-null    object \n",
      " 25  EmployeePhoto                         317 non-null    object \n",
      " 26  Position                              39 non-null     object \n",
      " 27  SalesTerritoryKey                     39 non-null     float64\n",
      " 28  SalesTerritoryAlternateKey            39 non-null     float64\n",
      " 29  SalesTerritoryRegion                  39 non-null     object \n",
      " 30  SalesTerritoryCountry                 39 non-null     object \n",
      " 31  SalesTerritoryGroup                   39 non-null     object \n",
      " 32  SalesTerritoryImage                   39 non-null     object \n",
      "dtypes: float64(5), int64(8), object(20)\n",
      "memory usage: 81.9+ KB\n",
      "SalesTerritoryCountry  SalesTerritoryRegion\n",
      "Australia              Australia               3\n",
      "Canada                 Canada                  4\n",
      "France                 France                  4\n",
      "Germany                Germany                 3\n",
      "United Kingdom         United Kingdom          3\n",
      "United States          Central                 5\n",
      "                       Northeast               3\n",
      "                       Northwest               5\n",
      "                       Southeast               4\n",
      "                       Southwest               5\n",
      "dtype: int64\n",
      "SalesTerritoryCountry\n",
      "Australia         47.764433\n",
      "Canada            41.592550\n",
      "France            41.592550\n",
      "Germany           47.764433\n",
      "United Kingdom    47.764433\n",
      "United States     39.909309\n",
      "Name: BaseRate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#ESERCIZIO7: dal database AdventureWorksDW importare le tabelle dimemployee e dimemployeesalesterritory come DataFrame\n",
    "''' effettuare un join tra i due DataFrame usando le colonne EmployeeKey\n",
    "    controllare la dimensione del DataFrame risultante: è quella attesa? \n",
    "    importare la tabella dimsalesterritory ed effettuare un join tra questa e il DataFrame risultante della join precedente, usando le colonne SalesTerritoryKey \n",
    "    su questo DataFrame contare quanti dipendenti ci sono per ogni paese (country) e per ogni regione (region)\n",
    "    valutare la media del BaseRate per ogni paese: ci sono differenze? '''\n",
    "\n",
    "import os\n",
    "import dotenv \n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "\n",
    "dotenv.load_dotenv(dotenv_path=\"adv_sql.env\", override=True,) #carica il file env\n",
    "\n",
    "username = os.getenv(\"username\") #credenziali\n",
    "password = os.getenv(\"password\")\n",
    "host = os.getenv(\"host\")\n",
    "dbname = os.getenv(\"dbname\")\n",
    "\n",
    "connection_string = f\"mysql+pymysql://{username}:{password}@{host}/{dbname}\" # stringa di connessione\n",
    "db_engine = sqlalchemy.create_engine(connection_string) #connessione al db\n",
    "\n",
    "#IMPORTO DIMEMPLOYEE E DIMEMPLOYEESALESTERRITORY\n",
    "query1 = \"SELECT * FROM dimemployee\"\n",
    "employee = pd.read_sql(query1, db_engine)\n",
    "\n",
    "query2 = \"SELECT * FROM dimemployeesalesterritory\"\n",
    "sales_employee = pd.read_sql(query2, db_engine)\n",
    "\n",
    "#employee.info()\n",
    "#sales_employee.info()\n",
    "\n",
    "employee = employee.set_index(\"EmployeeKey\") #setto gli indici\n",
    "sales_employee = sales_employee.set_index(\"EmployeeKey\")\n",
    "\n",
    "joined = employee.join(sales_employee) #join\n",
    "#print(joined.head(10))\n",
    "\n",
    "#print(joined.info()) #dimensione join\n",
    "\n",
    "#IMPORTO DIMSALESTERRITORY\n",
    "query3 = \"SELECT * FROM dimsalesterritory\"\n",
    "sales_territory = pd.read_sql(query3, db_engine)\n",
    "\n",
    "#sales_territory.info()\n",
    "\n",
    "joined2 = joined.merge(sales_territory, how=\"left\", on=\"SalesTerritoryKey\") #faccio un merge per colonna\n",
    "joined2.info()\n",
    "\n",
    "dipendenti = joined2.groupby([\"SalesTerritoryCountry\", \"SalesTerritoryRegion\"]).size() #numero dipendenti per region e country\n",
    "print(dipendenti)\n",
    "\n",
    "media_baserate = joined2.groupby(\"SalesTerritoryCountry\")[\"BaseRate\"].mean() #media di baserate in base al paese\n",
    "print(media_baserate)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epicode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
